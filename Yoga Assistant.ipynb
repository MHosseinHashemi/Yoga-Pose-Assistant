{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38db4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88e1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import winsound\n",
    "import time\n",
    "from IPython.display import Audio\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67d5b0",
   "metadata": {},
   "source": [
    "# Helper Image\n",
    "Here i need to define a function to get the cordinates back from each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c9ec8d",
   "metadata": {},
   "source": [
    "<img src = '68747470733a2f2f692e696d6775722e636f6d2f336a38425064632e706e67.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf5746b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Latest version\"\"\"\n",
    "# Angle calculator \n",
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # 1st body cordinate\n",
    "    b = np.array(b) # 2nd body cordinate\n",
    "    c = np.array(c) # 3rd body cordinate\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0]) \n",
    "    # calculate the corresponding angle in radians, then convert it to degress\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ae9cf",
   "metadata": {},
   "source": [
    "# Work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81e4b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the countdown func.\n",
    "\n",
    "# def countdown(t):\n",
    "    \n",
    "#     while t:\n",
    "#         mins, secs = divmod(t, 60)\n",
    "#         timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "#         cv2.putText(image, ('{:02d}:{:02d}'.format(mins, secs)), \n",
    "#                     tuple(np.multiply((0.025,0.12), [640, 480]).astype(int)), \n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 190), 2, cv2.LINE_AA\n",
    "#                    )\n",
    "#         time.sleep(1)\n",
    "#         t -= 1\n",
    "        \n",
    "#     cv2.putText(image, ('Done!'), \n",
    "#                             tuple(np.multiply((0.025,0.20), [640, 480]).astype(int)), \n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 250, 0), 2, cv2.LINE_AA\n",
    "#                            )\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2caef697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def countdown(t):\n",
    "#     while t:\n",
    "#         mins, secs = divmod(t, 60)\n",
    "#         timer = '{:02d}:{:02d}'.format(mins, secs)\n",
    "#         print(timer, end=\"\\r\")\n",
    "#         time.sleep(1)\n",
    "#         t -= 1\n",
    "        \n",
    "#     print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba9f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract landmarks\n",
    "# def export_landmarks(processed_image, op_code):\n",
    "#     landmarks = processed_image.pose_landmarks.landmark\n",
    "#     # Extract the landmarks\n",
    "#     LEFT_SHOULDER = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "#     RIGHT_SHOULDER = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "#     LEFT_FOOT = landmarks[mp_pose.PoseLandmark.LEFT_FOOT.value].x, landmarks[mp_pose.PoseLandmark.LEFT_FOOT.value].y\n",
    "#     RIGHT_FOOT = landmarks[mp_pose.PoseLandmark.RIGHT_FOOT.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_FOOT.value].y\n",
    "#     LEFT_KNEE = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y\n",
    "#     RIGHT_KNEE = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y\n",
    "#     LEFT_ELBOW = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "#     RIGHT_ELBOW = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y\n",
    "#     LEFT_WRIST = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "#     RIGHT_WRIST = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y\n",
    "#     LEFT_HIP = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y\n",
    "#     RIGHT_HIP = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y\n",
    "#     NOSE = landmarks[mp_pose.PoseLandmark.NOSE.value].x, landmarks[mp_pose.PoseLandmark.NOSE.value].y\n",
    "    \n",
    "#     if op_code == 'Boat':\n",
    "#         # According to the Boat exercise definition, we need to have 60 degree's angle between Hip and knee and shoulder\n",
    "#         L_angle = calculate_angle(LEFT_SHOULDER,LEFT_HIP,LEFT_KNEE)\n",
    "        \n",
    "#     return L_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b615565",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfddb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract landmarks\n",
    "def export_landmarks(processed_image):\n",
    "    landmarks = processed_image.pose_landmarks.landmark\n",
    "    # Extract the landmarks\n",
    "    LEFT_SHOULDER = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "    RIGHT_SHOULDER = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "    LEFT_FOOT = landmarks[mp_pose.PoseLandmark.LEFT_FOOT.value].x, landmarks[mp_pose.PoseLandmark.LEFT_FOOT.value].y\n",
    "    RIGHT_FOOT = landmarks[mp_pose.PoseLandmark.RIGHT_FOOT.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_FOOT.value].y\n",
    "    LEFT_KNEE = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y\n",
    "    RIGHT_KNEE = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y\n",
    "    LEFT_ELBOW = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "    RIGHT_ELBOW = landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y\n",
    "    LEFT_WRIST = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "    RIGHT_WRIST = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y\n",
    "    LEFT_HIP = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y\n",
    "    RIGHT_HIP = landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y\n",
    "    NOSE = landmarks[mp_pose.PoseLandmark.NOSE.value].x, landmarks[mp_pose.PoseLandmark.NOSE.value].y\n",
    "        \n",
    "    return LEFT_SHOULDER,LEFT_HIP,LEFT_KNEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f9dc8",
   "metadata": {},
   "source": [
    "# Hand Landmark Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f383e8c",
   "metadata": {},
   "source": [
    "<img src = \"68747470733a2f2f692e696d6775722e636f6d2f717052414365722e706e67.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a969dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Latest version\"\"\"\n",
    "# Extract landmarks\n",
    "def export_body_landmarks_(input_file):\n",
    "    landmarks = input_file.pose_landmarks.landmark\n",
    "    # Extract the landmarks\n",
    "    SHOULDER = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y\n",
    "    ANKLE = landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y\n",
    "    KNEE = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y\n",
    "    ELBOW = landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y\n",
    "    WRIST = landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y\n",
    "    HIP = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y\n",
    "        \n",
    "    return SHOULDER,ANKLE,KNEE,ELBOW,WRIST,HIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0487288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract landmarks\n",
    "def export_hand_landmarks_(input_file):\n",
    "    for hand in results.multi_hand_landmarks:\n",
    "        # Extract the landmarks\n",
    "        T = hand.landmark[map_hands.HandLandmark.THUMB_TIP.value].x, hand.landmark[map_hands.HandLandmark.THUMB_TIP.value].y\n",
    "        I = hand.landmark[map_hands.HandLandmark.INDEX_FINGER_TIP.value].x, hand.landmark[map_hands.HandLandmark.INDEX_FINGER_TIP.value].y\n",
    "        M = hand.landmark[map_hands.HandLandmark.MIDDLE_FINGER_TIP.value].x, hand.landmark[map_hands.HandLandmark.MIDDLE_FINGER_TIP.value].y\n",
    "        R = hand.landmark[map_hands.HandLandmark.RING_FINGER_TIP.value].x, hand.landmark[map_hands.HandLandmark.RING_FINGER_TIP.value].y\n",
    "        P = hand.landmark[map_hands.HandLandmark.PINKY_TIP.value].x, hand.landmark[map_hands.HandLandmark.PINKY_TIP.value].y\n",
    "        \n",
    "    return T,I,M,R,P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c7a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for landmark in map_hands.HandLandmark:\n",
    "#     print(landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "383be29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Im going to calculate the distance between each two finger tips then decide the correspounding number\n",
    "def distance_caluclator(Thumb,Index,Middle,Ring,Pinky):\n",
    "    dist_1 = round(math.dist(Thumb,Index), 4)\n",
    "    dist_2 = round(math.dist(Index,Middle), 4)\n",
    "    dist_3 = round(math.dist(Middle,Ring), 4)\n",
    "    dist_4 = round(math.dist(Ring,Pinky), 4)\n",
    "    \n",
    "    return dist_1, dist_2, dist_3, dist_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # To improve performance, optionally mark the image\n",
    "        # as not writeable to pass by reference.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Then after the processing set it to true \n",
    "        # to draw pose annotations\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        try :\n",
    "            \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            # Extract the landmarks\n",
    "            SHOULDER = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y\n",
    "            \n",
    "            HIP = landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y\n",
    "\n",
    "            KNEE = landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y\n",
    "\n",
    "            # According to the Boat exercise definition, we need to have specific angles between \n",
    "            # Hip and knee and shoulder\n",
    "            # And we need  to calculate it from three different angles\n",
    "            angle_1 = round(calculate_angle(SHOULDER,HIP,KNEE)) \n",
    "            angle_2 = round(calculate_angle(HIP,KNEE,SHOULDER)) \n",
    "            angle_3 = round(calculate_angle(KNEE,SHOULDER,HIP)) \n",
    "\n",
    "            cv2.putText(image, (f'Angle: {angle_1}'), \n",
    "                            tuple(np.multiply(HIP, [1280, 720]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                           )\n",
    "            cv2.putText(image, (f'Angle: {angle_2}'), \n",
    "                            tuple(np.multiply(KNEE, [1280, 720]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                           )\n",
    "            cv2.putText(image, (f'Angle: {angle_3}'), \n",
    "                            tuple(np.multiply(SHOULDER, [1280, 720]).astype(int)), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                           )\n",
    "            \n",
    "            # Adding pose criteria\n",
    "            if angle_1 in range(24,41) and angle_2 in range(85,95) and angle_3 in range(50,61):    \n",
    "                state = 'Start'\n",
    "                cv2.putText(image, ('Boat Pose'), \n",
    "                        tuple(np.multiply((0.035,0.25), [854, 480]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 3, (0,150,0), 3, cv2.LINE_AA\n",
    "                        )\n",
    "                \n",
    "            else:\n",
    "                state = None\n",
    "                    \n",
    "        except : \n",
    "            pass\n",
    "        \n",
    "        # Changing the colors of annotations\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                mp_drawing.DrawingSpec(color=(0, 0, 0), thickness=4,circle_radius=6),\n",
    "                                mp_drawing.DrawingSpec(color=(0, 0, 180), thickness=2,circle_radius=2))\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Yoga Assistant', image)\n",
    "\n",
    "        # Break the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8e73d",
   "metadata": {},
   "source": [
    "# HandPose Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8769a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_map_drawing = mp.solutions.drawing_utils\n",
    "map_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f7bc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gesture_decoder(distance_1, distance_2, distance_3, distance_4):           \n",
    "            \n",
    "            if ((0.10 < d_1 < 0.35) and (0.13 < d_2 < 0.42) and (0.010 < d_3 < 0.080) and (0.010 < d_4 <0.070)):    \n",
    "                cv2.putText(image, ('First Pose ...'), \n",
    "                        tuple(np.multiply((0.035,0.35), [640, 480]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0,200,0), 1, cv2.LINE_AA\n",
    "                        )\n",
    "                state = \"First\"\n",
    "                \n",
    "            if ((0.10 < d_1 < 0.35) and (0.030 < d_2 < 0.12) and (0.14 < d_3 < 0.37) and (0.010 < d_4 <0.070)):    \n",
    "                cv2.putText(image, ('Second Pose ...'), \n",
    "                        tuple(np.multiply((0.035,0.35), [640, 480]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0,200,0), 1, cv2.LINE_AA\n",
    "                        )\n",
    "                state = \"Second\"\n",
    "                \n",
    "            else:\n",
    "                cv2.putText(image, ('Make sure to have a normal hand getsture'), \n",
    "                        tuple(np.multiply((0.035,0.65), [640, 480]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.40, (0,0,250), 1, cv2.LINE_AA\n",
    "                        )\n",
    "            \n",
    "#             return state\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05706966",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      9\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Flip on horizontal to make true judgement because the camera feed is mirrored\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     image\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Here im going to use a Hand Pose Estimator to Detect the Number shown by User's hand and Based on the label\n",
    " Its going to use that prediction to classifiy the landmarks \"\"\"\n",
    "state = None\n",
    "    \n",
    "cap = cv2.VideoCapture('Test2.mp4')\n",
    "\n",
    "with map_hands.Hands(min_detection_confidence=0.8, min_tracking_confidence=0.5) as hands: \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Flip on horizontal to make true judgement because the camera feed is mirrored\n",
    "        image.flags.writeable = False\n",
    "        results = hands.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            # Taking hand cordinations\n",
    "            THUMB,INDEX,MIDDLE,RING,PINKY = export_hand_landmarks_(results)            \n",
    "            # Calculating the distance metric\n",
    "            d_1, d_2, d_3, d_4 = distance_caluclator(THUMB,INDEX,MIDDLE,RING,PINKY)\n",
    "            \n",
    "#             cv2.putText(image, (\"Distance Between Thumb Tip & Index Tip : {:.4f}\".format(d_1)), \n",
    "#                         tuple(np.multiply((0.035,0.10), [640, 480]).astype(int)), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA\n",
    "#                         )\n",
    "#             cv2.putText(image, (\"Distance Between Index Tip & Middle Tip : {:.4f}\".format(d_2)), \n",
    "#                         tuple(np.multiply((0.035,0.15), [640, 480]).astype(int)), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA\n",
    "#                         )\n",
    "#             cv2.putText(image, (\"Distance Between Middle Tip & Ring Tip : {:.4f}\".format(d_3)), \n",
    "#                         tuple(np.multiply((0.035,0.20), [640, 480]).astype(int)), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA\n",
    "#                             )\n",
    "#             cv2.putText(image, (\"Distance Between Ring Tip & Pinky Tip : {:.4f}\".format(d_4)), \n",
    "#                         tuple(np.multiply((0.035,0.25), [640, 480]).astype(int)), \n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA\n",
    "#                         )\n",
    "            cv2.putText(image, ('Choose your preferred Yoga pose :  1.Boat  2.Warrior II'), \n",
    "                    tuple(np.multiply((0.025,0.075), [640, 480]).astype(int)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.50, (0,0,200), 1, cv2.LINE_AA\n",
    "                    )\n",
    "            \"\"\"This method is not very efficient because the related conditions are super hard to distinguish\"\"\"\n",
    "            #Adding pose criteria\n",
    "            gesture_decoder(d_1, d_2, d_3, d_4)\n",
    "            \n",
    "            # I am going to conclude the pose tracking based on the returned state\n",
    "            \n",
    "#             if state == \"First\":\n",
    "#                 pass\n",
    "#             if state == \"Second\":\n",
    "#                 pass\n",
    "            \n",
    "            \n",
    "            # Draw the connections\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):            \n",
    "                hand_map_drawing.draw_landmarks(image, hand, map_hands.HAND_CONNECTIONS, \n",
    "                                        hand_map_drawing.DrawingSpec(color=(0, 0, 250), thickness=2, circle_radius=4),\n",
    "                                        hand_map_drawing.DrawingSpec(color=(0, 0, 250), thickness=2, circle_radius=2),\n",
    "                                        )\n",
    "        \n",
    "        cv2.imshow('Hand Gesture Tracker', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed9ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39251232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd11e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedab73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c6644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Latest Version\"\"\"\n",
    "cap = cv2.VideoCapture('Test.mp4')\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # To improve performance, optionally mark the image\n",
    "        # as not writeable to pass by reference.\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        results = pose.process(image)\n",
    "        \n",
    "        # Then after the processing set it to true \n",
    "        # to draw pose annotations\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Extract the landmarks\n",
    "        SHOULDER,ANCLE,KNEE,ELBOW,WRIST,HIP = export_body_landmarks_(results)\n",
    "            \n",
    "        # According to the Boat exercise definition, we need to have specific angles between \n",
    "        # Hip and knee and shoulder\n",
    "        # And we need  to calculate it from three different angles\n",
    "        angle_1 = round(calculate_angle(SHOULDER,HIP,KNEE)) \n",
    "        angle_2 = round(calculate_angle(HIP,KNEE,SHOULDER)) \n",
    "        angle_3 = round(calculate_angle(KNEE,SHOULDER,HIP)) \n",
    "\n",
    "        cv2.putText(image, (f'Angle: {angle_1}'), \n",
    "                        tuple(np.multiply(HIP, [1280, 720]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "        cv2.putText(image, (f'Angle: {angle_2}'), \n",
    "                        tuple(np.multiply(KNEE, [1280, 720]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "        cv2.putText(image, (f'Angle: {angle_3}'), \n",
    "                        tuple(np.multiply(SHOULDER, [1280, 720]).astype(int)), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                        )\n",
    "            \n",
    "        # Adding pose criteria\n",
    "        if angle_1 in range(24,41) and  angle_2 in range(85,95) and angle_3 in range(50,61):    \n",
    "            state = 'Start'\n",
    "            cv2.putText(image, ('Boat Pose'), \n",
    "                    tuple(np.multiply((0.035,0.25), [854, 480]).astype(int)), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 3, (0,150,0), 3, cv2.LINE_AA\n",
    "                    )\n",
    "                \n",
    "        else:\n",
    "            state = None\n",
    "                    \n",
    "        \n",
    "        # Changing the colors of annotations\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                            mp_drawing.DrawingSpec(color=(0, 0, 0), thickness=4,circle_radius=6),\n",
    "                            mp_drawing.DrawingSpec(color=(0, 0, 180), thickness=2,circle_radius=2))\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Yoga Assistant', image)\n",
    "\n",
    "        # Break the loop\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-2022",
   "language": "python",
   "name": "gpu-2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
